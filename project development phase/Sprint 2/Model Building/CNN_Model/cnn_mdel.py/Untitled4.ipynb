{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Part 1 - Building the CNN\n",
        "#importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import optimizers\n",
        "\n",
        "# Initialing the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "# Step 1 - Convolution Layer\n",
        "classifier.add(Convolution2D(32, 3,  3, input_shape = (64, 64, 3), activation = 'relu'))\n",
        "\n",
        "#step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "# Adding second convolution layer\n",
        "classifier.add(Convolution2D(32, 3,  3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "#Adding 3rd Concolution Layer\n",
        "classifier.add(Convolution2D(64, 3,  3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
        "\n",
        "\n",
        "#Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "#Step 4 - Full Connection\n",
        "classifier.add(Dense(256, activation = 'relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "#Compiling The CNN\n",
        "classifier.compile(\n",
        "              optimizer = 'adam',\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "#Part 2 Fittting the CNN to the image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'Data/train',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'Data/test',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "model = classifier.fit_generator(\n",
        "        training_set,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=100,\n",
        "        validation_data = test_set,\n",
        "        validation_steps = 6500\n",
        "      )\n",
        "\n",
        "#Saving the model\n",
        "import h5py\n",
        "classifier.save('Trained_Model.h5')\n",
        "\n",
        "print(model.history.keys())\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(model.history['acc'])\n",
        "plt.plot(model.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(model.history['loss'])\n",
        "plt.plot(model.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GkTtSOizqlK7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}